{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rgNsRaRyoeBD",
        "outputId": "f3ea088f-7890-46ac-8ff0-79df2a62dd45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using device: cuda\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import tensorflow as tf\n",
        "\n",
        "USE_GPU = True\n",
        "\n",
        "dtype = torch.float64 # we will be using float throughout this tutorial\n",
        "device = torch.device('cuda') if (USE_GPU and torch.cuda.is_available()) else torch.device('cpu')\n",
        "print('using device:', device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "8-aSQ4Kp_fgD"
      },
      "outputs": [],
      "source": [
        "def pay_off(S,r,K,dt):\n",
        "  return torch.maximum(K- S,torch.zeros_like(S))\n",
        "\n",
        "\n",
        "def simulate_path(M, T, n, r, vol, S, K, dt):\n",
        "    nudt = (r - 0.5 * vol**2) * dt\n",
        "    lnS = np.log(S)\n",
        "\n",
        "    # Méthode de Monte Carlo\n",
        "    Z = np.random.normal(size=(M,n))\n",
        "    L = np.random.normal(size=(M,n)) #new random variable\n",
        "    dW = np.sqrt(dt) * Z  #it's the simulation of the dWt_i we'll need in each iteration\n",
        "    delta_lnSt = nudt + vol*dW\n",
        "\n",
        "    LnS_s = np.zeros([M, n + 1])\n",
        "\n",
        "    # Set the initial values\n",
        "    LnS_s[:, 0] = lnS\n",
        "    # Compute cumulative sums using cumsum\n",
        "    LnS_s[:, 1:] = np.cumsum(delta_lnSt, axis=1)\n",
        "    LnS_s[:,1:] +=lnS\n",
        "\n",
        "    S = np.exp(LnS_s)\n",
        "    S_tensor = torch.tensor(S, device = device ,dtype=dtype)\n",
        "    dW_tensor = torch.tensor(dW, device = device ,dtype=dtype)\n",
        "    L_tensor = torch.tensor(L, device = device ,dtype=dtype)\n",
        "\n",
        "    return S_tensor,dW_tensor , L_tensor\n",
        "\n",
        "#Parametres\n",
        "\n",
        "T = 1\n",
        "n=50\n",
        "dt = T/n  #les t_i seront donc les i*dt.\n",
        "\n",
        "\n",
        "S = 36          # Prix de l'action\n",
        "K = 40           # Prix d'exercice\n",
        "vol = 0.2       # Volatilité (%)\n",
        "r = 0.06            # Taux sans risque (%)\n",
        "M = 100000  # Nombre de simulations\n",
        "\n",
        "\n",
        "S,dW ,L =simulate_path(M, T, n, r, vol, S, K, dt)\n",
        "X=torch.zeros([M,n+1], device = device ,dtype=dtype)\n",
        "Y=torch.zeros_like(X, device = device ,dtype=dtype)\n",
        "\n",
        "\n",
        "X[ :, n]=pay_off(S[:,n],r,K,dt)\n",
        "Y[ :, n]=X[ :, n]\n",
        "\n",
        "beta_dt=math.exp(-r*dt)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "class SpecificModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SpecificModel, self).__init__()\n",
        "        self.branch1 = nn.Sequential(\n",
        "            nn.Linear(1, 20),\n",
        "            # nn.BatchNorm1d(50),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(20, 20),\n",
        "            # nn.BatchNorm1d(50),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(20, 1)\n",
        "        )\n",
        "        self.branch2 = nn.Sequential(\n",
        "            nn.Linear(1, 20),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(20, 20),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(20, 20),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(20, 1)\n",
        "        )\n",
        "        self.branch3 = nn.Sequential(\n",
        "            nn.Linear(1, 20),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(20, 20),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(20, 20),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(20, 20),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(20, 1)\n",
        "        )\n",
        "        self.branch4 = nn.Sequential(\n",
        "            nn.Linear(1, 20),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(20, 20),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(20, 20),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(20, 20),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(20, 20),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(20, 1)\n",
        "        )\n",
        "\n",
        "        self.optimizer = optim.Adam(self.parameters(), lr=0.001)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_branch1 = self.branch1(x)\n",
        "        x_branch2 = self.branch2(x)\n",
        "        x_branch3 = self.branch3(x)\n",
        "        x_branch4 = self.branch4(x)\n",
        "        concatenated_output = torch.cat((x_branch1, x_branch2, x_branch3, x_branch3), dim=1)\n",
        "        return concatenated_output\n",
        "\n",
        "    def custom_loss(self, Y_true, dW_true , dW_true_2 , L_true ,  y_pred):\n",
        "        return torch.mean(torch.square(Y_true - (y_pred[:, 0] + dW_true * y_pred[:, 1]+(dW_true_2-dt)*y_pred[:, 2]+L_true*y_pred[:, 3])))\n",
        "\n",
        "    def train_model(self, S_tensor, Y_tensor, dW_tensor, L_tensor , epochs=5, batch_size=32, validation_split=0.2):\n",
        "        torch.cuda.empty_cache()\n",
        "        combined_labels = torch.cat((Y_tensor.unsqueeze(1), dW_tensor.unsqueeze(1), L_tensor.unsqueeze(1)), dim=1)\n",
        "        dataset = TensorDataset(S_tensor, combined_labels)\n",
        "        train_size = int((1 - validation_split) * len(dataset))\n",
        "        val_size = len(dataset) - train_size\n",
        "        train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
        "        train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "        val_dataloader = DataLoader(val_dataset, batch_size=batch_size)\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            self.train()\n",
        "            total_loss = 0\n",
        "            for S_batch, labels_batch in train_dataloader:\n",
        "                self.optimizer.zero_grad()\n",
        "                outputs = self(S_batch)\n",
        "                loss = self.custom_loss(labels_batch[:, 0], labels_batch[:, 1] , labels_batch[:, 1]*labels_batch[:, 1] ,labels_batch[:, 2],  outputs)\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "                total_loss += loss.item()\n",
        "\n",
        "\n",
        "            val_loss = 0\n",
        "\n",
        "            if epoch % 3 == 0:\n",
        "                self.eval()\n",
        "                with torch.no_grad():\n",
        "                    for S_batch, labels_batch in val_dataloader:\n",
        "                        outputs = self(S_batch)\n",
        "                        val_loss += self.custom_loss(labels_batch[:, 0], labels_batch[:, 1], labels_batch[:, 1]*labels_batch[:, 1], labels_batch[:, 2] , outputs).item()\n",
        "\n",
        "                print(f\"Epoch {epoch+1}/{epochs}, Training Loss: {total_loss/len(train_dataset)}, Validation Loss: {val_loss/val_size}\")\n",
        "\n",
        "\n",
        "        self.eval()\n",
        "        with torch.no_grad():\n",
        "              outputs = self(S_tensor)\n",
        "        print(\"Training complete .\")\n",
        "\n",
        "        return outputs\n",
        "\n",
        "model = SpecificModel().to(device = device ,dtype=dtype)\n"
      ],
      "metadata": {
        "id": "O_Rr5mc237PA"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-cH8r8hu8xPh"
      },
      "outputs": [],
      "source": [
        "\n",
        "# The main loop :\n",
        "\n",
        "for i in range(n-1,0,-1):\n",
        "  #determination of phi and psi in one step\n",
        "  print( \"In the \", i ,\" th step :\")\n",
        "  outputs =  model.train_model(S[:,i].reshape(-1,1), beta_dt*Y[:,i+1].reshape(-1,1), dW[:,i].reshape(-1,1),L[:,i].reshape(-1,1))\n",
        "\n",
        "  psi_S=outputs[:,1]\n",
        "  phi_S=outputs[:,0]\n",
        "\n",
        "  X[ :, i]=beta_dt*X[:,i+1]-psi_S *dW[:,i] #to change it into (M,)\n",
        "  Y[ :, i]=beta_dt*Y[:,i+1]-psi_S *dW[:,i]\n",
        "\n",
        "  Z=pay_off(S[:,i],r,K,dt)\n",
        "\n",
        "  Y[ :, i] = torch.where(Z> phi_S, Z, Y[ :, i])\n",
        "  X[ :, i] = torch.where(Z> X[:,i], Z, X[ :, i])\n",
        "\n",
        "\n",
        "#Pour i =0 :\n",
        "#determination of phi and psi in two steps\n",
        "i=0\n",
        "outputs = model.train_model(S[:,i].reshape(-1,1), beta_dt*Y[:,i+1].reshape(-1,1), dW[:,i].reshape(-1,1),L[:,i].reshape(-1,1))\n",
        "\n",
        "psi_S=outputs[:,1]\n",
        "phi_S=outputs[:,0]\n",
        "\n",
        "X[ :, 0]=beta_dt*X[:,1]-psi_S *dW[:,0]\n",
        "Y[ :, 0]=beta_dt*Y[:,1]-psi_S *dW[:,0]\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "eNe1fLG9_xnB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e1b5d85-0a58-473f-9188-ec665f00d02d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5.851455488990885\n",
            "4.203136286169285\n",
            "1.6483192028215994\n"
          ]
        }
      ],
      "source": [
        "#Monté Carlo\n",
        "u0=torch.mean(X[:,0]).cpu().numpy()\n",
        "l0=torch.mean(Y[:,0]).cpu().numpy()\n",
        "print(u0)\n",
        "print(l0)\n",
        "print(np.abs(u0-l0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "dlx9jG8GSdJ_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2247b96-5a34-4317-a67c-ed70e3af4370"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.01249999999999929\n",
            "1.6358192028216\n"
          ]
        }
      ],
      "source": [
        "print(4.4887-4.4762)\n",
        "print(np.abs(np.abs(u0-l0)-(4.4887-4.4762)))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}